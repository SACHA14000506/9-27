{"ef784c807657dae420ea25a499137e52b039f989":{"changes":{"doc\/whats_new\/v1.6.rst":"MODIFY","sklearn\/neural_network\/tests\/test_mlp.py":"MODIFY","sklearn\/neural_network\/_multilayer_perceptron.py":"MODIFY"},"diff":{"doc\/whats_new\/v1.6.rst":[{"add":["377",":mod:`sklearn.neural_network`","378",".............................","379","","380","- |Fix| :class:`neural_network.MLPRegressor` does no longer crash when the model","381","  diverges and that `early_stopping` is enabled. :pr:`29773` by","382","  :user:`Marc Bresson <MarcBresson>`.","383",""],"delete":[]}],"sklearn\/neural_network\/tests\/test_mlp.py":[{"add":["26","from sklearn.utils._testing import (","27","    assert_allclose,","28","    assert_almost_equal,","29","    assert_array_equal,","30","    ignore_warnings,","31",")","967","","968","","969","def test_mlp_diverging_loss():","970","    \"\"\"Test that a diverging model does not raise errors when early stopping is enabled.","971","","972","    Non-regression test for:","973","    https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/29504","974","    \"\"\"","975","    mlp = MLPRegressor(","976","        hidden_layer_sizes=100,","977","        activation=\"identity\",","978","        solver=\"sgd\",","979","        alpha=0.0001,","980","        learning_rate=\"constant\",","981","        learning_rate_init=1,","982","        shuffle=True,","983","        max_iter=20,","984","        early_stopping=True,","985","        n_iter_no_change=10,","986","        random_state=0,","987","    )","988","","989","    mlp.fit(X_iris, y_iris)","990","","991","    # In python, float(\"nan\") != float(\"nan\")","992","    assert str(mlp.validation_scores_[-1]) == str(np.nan)","993","    assert isinstance(mlp.validation_scores_[-1], float)"],"delete":["15","from numpy.testing import (","16","    assert_allclose,","17","    assert_almost_equal,","18","    assert_array_equal,","19",")","31","from sklearn.utils._testing import ignore_warnings"]}],"sklearn\/neural_network\/_multilayer_perceptron.py":[{"add":["394","        self._best_coefs = [c.copy() for c in self.coefs_]","395","        self._best_intercepts = [i.copy() for i in self.intercepts_]","396","","706","            # compute validation score (can be NaN), use that for stopping","707","            val_score = self._score(X_val, y_val)","708","","709","            self.validation_scores_.append(val_score)","763","    def _score_with_function(self, X, y, score_function):","764","        \"\"\"Private score method without input validation.\"\"\"","765","        # Input validation would remove feature names, so we disable it","766","        y_pred = self._predict(X, check_input=False)","767","","768","        if np.isnan(y_pred).any() or np.isinf(y_pred).any():","769","            return np.nan","770","","771","        return score_function(y, y_pred)","772","","1188","        return super()._score_with_function(X, y, score_function=accuracy_score)","1628","        return super()._score_with_function(X, y, score_function=r2_score)"],"delete":["703","            # compute validation score, use that for stopping","704","            self.validation_scores_.append(self._score(X_val, y_val))","1173","        \"\"\"Private score method without input validation\"\"\"","1174","        # Input validation would remove feature names, so we disable it","1175","        return accuracy_score(y, self._predict(X, check_input=False))","1615","        \"\"\"Private score method without input validation\"\"\"","1616","        # Input validation would remove feature names, so we disable it","1617","        y_pred = self._predict(X, check_input=False)","1618","        return r2_score(y, y_pred)"]}]}}}